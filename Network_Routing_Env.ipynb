{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b508c735-59ea-4955-b110-f5c10fd88408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b3144c-1d05-4e33-afb0-edf7d6fdc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WanEnv(gym.Env):\n",
    "  \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "  metadata = {'render.modes': ['human']}\n",
    "\n",
    "  def __init__(self, df):\n",
    "    super(WanEnv, self).__init__()\n",
    "    # Define action and observation space\n",
    "    # They must be gym.spaces objects\n",
    "    # Example when using discrete actions:\n",
    "    self.action_space = spaces.MultiDiscrete([2,3,3,3,3])\n",
    "    # Example for using image as input:\n",
    "    self.observation_space = spaces.dict({\n",
    "                                         'N1Q' : MultiDiscrete[5,5,5,5,5],\n",
    "                                         'N2Q' : MultiDiscrete[5,5,5,5,5],\n",
    "                                         'N3Q' : MultiDiscrete[5,5,5,5,5],\n",
    "                                         'N4Q' : MultiDiscrete[5,5,5,5,5],\n",
    "                                         'N5Q' : MultiDiscrete[5,5,5,5,5]}\n",
    "                                        )\n",
    "    #(low=0, high=255, shape=\n",
    "     #               (HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "  def step(self, action):\n",
    "    # Execute one time step within the environment\n",
    "        self.take_action(action)\n",
    "        reward, ob = self.take_action(action)\n",
    "        return ob, reward\n",
    "    \n",
    "  def take_action(self, action):\n",
    "        self.episode_over = self.backend.switch_link(action)\n",
    "                \n",
    "        self.ticks += 1\n",
    "        tmp = []\n",
    "\n",
    "        # check if episode ended by ERROR, then mark it in 'info'\n",
    "        if self.episode_over:\n",
    "            logging.info ('Episode ended by ERROR')\n",
    "            self.info['exit_status'] = 'ERROR'\n",
    "\n",
    "        # else Stop if max ticks over\n",
    "        elif self.ticks == self.MAX_TICKS:\n",
    "            logging.info ('Max ticks over, ending episode')\n",
    "            self.episode_over = True\n",
    "            self.info['exit_status'] = 'NORMAL'\n",
    "    \n",
    "  def reset(self):\n",
    "    # Reset the state of the environment to an initial state\n",
    "    self.N1Q = df.loc[:,[\"N1Q\"]]\n",
    "    self.N2Q = df.loc[:,[\"N2Q\"]]\n",
    "    self.N3Q = df.loc[:,[\"N3Q\"]]\n",
    "    self.N4Q = df.loc[:,[\"N4Q\"]]\n",
    "    self.N5Q = df.loc[:,[\"N5Q\"]]\n",
    "    self.reward=0\n",
    "    self.done = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9fcafdb0-96bb-4d2f-8a81-3cb28df4eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   N1Q  N2Q  N3Q  N4Q  N5Q\n",
      "0    3    4    1    2    3\n",
      "1    2    5    1    5    1\n",
      "2    0    0    0    0    0\n",
      "3    0    0    0    0    0\n",
      "4    0    0    0    0    0\n",
      "[[3 4 1 2 3]\n",
      " [2 5 1 5 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[2, 1, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[3,4,1,2,3],[2,5,1,5,1],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]])\n",
    "action = [2,1,2,3,3]\n",
    "df = pd.DataFrame(data, columns=[\"N1Q\",\"N2Q\",\"N3Q\",\"N4Q\",\"N5Q\"])\n",
    "print(df)\n",
    "print(data)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "11906017-26b6-4518-a68e-b4ca28be98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcontrol(l, size, filler):    ## Functon used after each timestep to keep a constant queuee size \n",
    "    length = len(l)\n",
    "    if length>size:\n",
    "        return l[:5]\n",
    "    elif length<size:\n",
    "        for i in range(0,size-length):\n",
    "            l.append(filler)\n",
    "            return l\n",
    "    else:\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "365940b7-97cb-48bd-9d11-df414159a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_action(df,action):\n",
    "\n",
    "    print(df)\n",
    "    data = df.to_numpy()\n",
    "    q=data.tolist()\n",
    "    tmp = q.pop(0)\n",
    "\n",
    "    #Actions (0: No routing for all)\n",
    "    #N1, 1:route to N2, 2: route to N5\n",
    "    #N2, 1:route to N4, 2: route to N3, 3: route to N1\n",
    "    #N3, 1:route to N2, 2: route to N4, 3: route to N5\n",
    "    #N4, 1:route to N5, 2: route to N3, 3: route to N2\n",
    "    #N5, 1:route to N1, 2: route to N3, 3: route to N4\n",
    "    q1 = data[:,0].tolist()[1:]   \n",
    "    q2 = data[:,1].tolist()[1:]\n",
    "    q3 = data[:,2].tolist()[1:]      ## Seperating into individual queues for manipulation since each one will\n",
    "    q4 = data[:,3].tolist()[1:]      ## receive different quantity\n",
    "    q5 = data[:,4].tolist()[1:]\n",
    "    count = 0                         ## counter managing the multidiscrete action space\n",
    "    reward = 0                        ## initializng reward for current episode\n",
    "    for i in action:\n",
    "        packet = tmp[count]\n",
    "        if count==0:\n",
    "            if i==1:\n",
    "                if packet!=2:\n",
    "                    q2.insert(0,packet)         ## Managing routing algorithm for each qeueu starting by q1 and \n",
    "                    reward += -1                ## along with each corresponding action, if the packet is routed \n",
    "                else:                           ## to its destination it disapears from our env and we get a +10 reward\n",
    "                    reward += 10                ## if not it is added to the top of the next queue with a reward of -1                \n",
    "            elif i==2:\n",
    "                if packet!=5:\n",
    "                    q5.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10                 ## if statement are determined by the available actions based on \n",
    "            count+=1                             ## network topology and encoded actions\n",
    "        elif count==1:\n",
    "            if i==1:\n",
    "                if packet!=4:\n",
    "                    q4.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10  \n",
    "            elif i==2:\n",
    "                if packet!=3:\n",
    "                    q3.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==3:\n",
    "                if packet!=1:\n",
    "                    q1.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            count+=1\n",
    "        elif count==2:\n",
    "            if i==1:\n",
    "                if packet!=2:\n",
    "                    q2.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==2:\n",
    "                if packet!=4:\n",
    "                    q4.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==3:\n",
    "                if packet!=5:\n",
    "                    q5.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            count+=1\n",
    "        elif count==3:\n",
    "            if i==1:\n",
    "                if packet!=5:\n",
    "                    q5.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==2:\n",
    "                if packet!=3:            \n",
    "                    q3.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==3:\n",
    "                if packet!=2:\n",
    "                    q2.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            count+=1\n",
    "        elif count==4:\n",
    "            if i==1:\n",
    "                if packet!=1:\n",
    "                    q1.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==2:\n",
    "                if packet!=3:\n",
    "                    q3.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            elif i==3:\n",
    "                if packet!=4:\n",
    "                    q4.insert(0,packet)\n",
    "                    reward += -1\n",
    "                else:\n",
    "                    reward += 10\n",
    "            count+=1\n",
    "\n",
    "\n",
    "    print(action)\n",
    "    q1=qcontrol(q1,5,0)                     ## qcontrol is called for each individual to ensure a constant queue size\n",
    "    q2=qcontrol(q2,5,0)                     ## according to our observation space definition\n",
    "    q3=qcontrol(q3,5,0)\n",
    "    q4=qcontrol(q4,5,0)\n",
    "    q5=qcontrol(q5,5,0)\n",
    "    new_state = np.array([q1,q2,q3,q4,q5]).T            ## reassembling o\n",
    "    new_state_pandas = pd.DataFrame(new_state, columns = [\"NQ1\",\"NQ2\",\"NQ3\",\"NQ4\",\"NQ%\"])\n",
    "    return new_state_pandas, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f88b4ee8-463d-4c9d-8ad7-8d6f9ad5abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   N1Q  N2Q  N3Q  N4Q  N5Q\n",
      "0    3    4    1    2    3\n",
      "1    2    5    1    5    1\n",
      "2    0    0    0    0    0\n",
      "3    0    0    0    0    0\n",
      "4    0    0    0    0    0\n",
      "[2, 1, 2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(action)\n",
    "new_state, reward = take_action(df,action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9e97ffdf-ab2c-48bd-bf06-adb8f8f878d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NQ1  NQ2  NQ3  NQ4  NQ%\n",
      "0    2    5    1    3    3\n",
      "1    0    0    0    1    1\n",
      "2    0    0    0    5    0\n",
      "3    0    0    0    0    0\n",
      "4    0    0    0    0    0\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(new_state)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f2328-4b62-4a9a-9109-a478295b1c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
